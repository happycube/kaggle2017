{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6bc9b087-c98b-bd97-66c6-92c5d01242d4"
   },
   "source": [
    "Using this just for RandomForestClassifier - there's also ExtraTrees and RandomForestRegressors, but they didn't help my OOB, so they're not getting run here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import sklearn.cluster\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('fin-dprep-train.pkl')\n",
    "test_df = pd.read_pickle('fin-dprep-test.pkl')\n",
    "features_to_use = pickle.load(open('fin-dprep-flist.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medium_price = pd.read_pickle('fin-medium-price.pkl')\n",
    "\n",
    "train_df = pd.merge(train_df, medium_price, left_on='listing_id', right_index=True)\n",
    "test_df = pd.merge(test_df, medium_price, left_on='listing_id', right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df['predicted_price_diff'] = np.log(df.predicted_price) - np.log(df.price)\n",
    "    df['predicted_price_ratio'] = np.log(df.predicted_price) / np.log(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_group 0.0488733992543\n",
      "price_ratio 0.0488733992543\n",
      "manager_shortdesc_rate 0.0688725887502\n",
      "manager_building0_rate 0.0688725887502\n",
      "manager_0feature_rate 0.0688725887502\n",
      "manager_median_price 0.0688725887502\n",
      "manager_lazy_rate 0.0688725887502\n"
     ]
    }
   ],
   "source": [
    "# fill in the NaN's.\n",
    "\n",
    "for t in train_df.keys():\n",
    "    nacount = train_df[t].isnull().sum()\n",
    "    if nacount:\n",
    "#        nacount_test = test_df[t].isnull().sum()\n",
    "        print(t, nacount / len(train_df))#, nacount_test / len(test_df))\n",
    "        \n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeansProcessor:\n",
    "    def __init__(self, key, outkey = None, tgt = 'interest'):\n",
    "        self.key = key\n",
    "        self.outkey = key if outkey is None else outkey\n",
    "        \n",
    "        self.count = {}\n",
    "        self.means = {}\n",
    "        self.std = {}\n",
    "        self.global_means = {}\n",
    "        \n",
    "        self.tgt = tgt\n",
    "        \n",
    "        self.outkeys = [self.outkey + '_level', self.outkey + '_level_std']\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.global_means[self.outkey + '_level'] = df[self.tgt].mean()\n",
    "        self.global_means[self.outkey + '_level_std'] = df[self.tgt].std()\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            \n",
    "            self.count[k[0]] = len(k[1])\n",
    "\n",
    "            if len(k[1]) < 0:\n",
    "                self.means[k[0]] = np.nan\n",
    "                self.std[k[0]] = np.nan\n",
    "            else:\n",
    "                self.means[k[0]] = np.mean(k[1][self.tgt])\n",
    "                self.std[k[0]] = np.std(k[1][self.tgt])\n",
    "            \n",
    "    def predict(self, df, nans = False):\n",
    "        for l in self.outkeys:\n",
    "            df[l] = np.nan if nans else self.global_means[l]\n",
    "            \n",
    "        df[self.outkey + '_count'] = 0\n",
    "            \n",
    "        for k in df.groupby(self.key, sort=False):\n",
    "            if k[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            if k[0] in self.means:\n",
    "                df.loc[k[1].index, self.outkey + '_count'] = self.count[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level'] = self.means[k[0]]\n",
    "                df.loc[k[1].index, self.outkey + '_level_std'] = self.std[k[0]]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_features(self):\n",
    "        return self.outkeys.copy() + [self.outkey + '_count']\n",
    "\n",
    "# i kept the same index randomization (with fixed seed) so I could validate this code against\n",
    "# the original...\n",
    "\n",
    "target_num_map = {'low':0, 'medium':1, 'high':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "def proc_fold(fold):\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    \n",
    "    cv_train = train_df.iloc[train_index]\n",
    "    cv_valid = train_df.iloc[test_index][['interest_level', 'manager_id', 'building_id']]\n",
    "    cv_test = test_df.copy()\n",
    "    \n",
    "    m_build = MeansProcessor('building_id', 'building_sort')\n",
    "    m_build.fit(cv_train)\n",
    "    cv_valid = m_build.predict(cv_valid)\n",
    "    cv_test = m_build.predict(cv_test)\n",
    "\n",
    "    m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "    m_mgr.fit(cv_train)\n",
    "    cv_valid = m_mgr.predict(cv_valid)\n",
    "    cv_test = m_mgr.predict(cv_test)\n",
    "\n",
    "    m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "    m_comb.fit(cv_train)\n",
    "    cv_valid = m_comb.predict(cv_valid)\n",
    "    cv_test = m_comb.predict(cv_test)\n",
    "\n",
    "    return cv_train, cv_valid, cv_test\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "folds = [(k[0], k[1]) for k in kf.split(list(range(train_df.shape[0])), train_y)]\n",
    "\n",
    "#with Pool(5) as pool:\n",
    "#    rv = pool.map(proc_fold, folds)\n",
    "\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    rv = pickle.load(open('0422-model-groupfeatures_nonan.pkl', 'rb'))\n",
    "except:\n",
    "    with Pool(5) as pool:\n",
    "        rv = pool.map(proc_fold, folds)\n",
    "\n",
    "        pickle.dump(rv, open('0422-model-groupfeatures_nonan.pkl', 'wb'))\n",
    "\n",
    "# dummies to get feature id's\n",
    "m_build = MeansProcessor('building_id', 'building_sort')\n",
    "m_mgr = MeansProcessor('manager_id', 'manager_sort')\n",
    "m_comb = MeansProcessor(['building_id', 'manager_id'], 'mb_comb')\n",
    "\n",
    "group_features = m_build.get_features() + m_mgr.get_features() + m_comb.get_features()\n",
    "\n",
    "#cv_test = [r[2] for r in rv]\n",
    "cv_test = []\n",
    "for r in rv:\n",
    "    cv_test.append(test_df.merge(r[2][group_features], left_index=True, right_index=True))\n",
    "\n",
    "cv_allvalid = pd.concat([r[1] for r in rv])\n",
    "\n",
    "train_df = train_df.merge(cv_allvalid[group_features], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "folds = [(k[0], k[1]) for k in kf.split(list(range(train_df.shape[0])), train_df.interest_cat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [train_df] + cv_test:\n",
    "    df['price_t'] = df['price_t'].clip(0, 13000)\n",
    "    df['price_per_room'] = df['price_per_room'].clip(0, 13000)\n",
    "    #df['density_lin005'] = df['density_lin005'].clip(-50, 50)\n",
    "    df['predicted_price_ratio'] = df['predicted_price_ratio'].clip(-50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:431: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:431: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df_normalized = train_df.copy()\n",
    "cvtest_normalized = [df.copy() for df in cv_test]\n",
    "\n",
    "train_df_normalized['listing_id_norm'] = train_df_normalized['listing_id']\n",
    "for df in cvtest_normalized:\n",
    "    df['listing_id_norm'] = df['listing_id']\n",
    "\n",
    "normalized_keys = []\n",
    "\n",
    "scaler = {}\n",
    "for f in train_df.keys():\n",
    "    if f[0:2] == 'f_' or f[0:3] == 'fm_':\n",
    "        train_df_normalized[f] = train_df_normalized[f].clip(0, 1)\n",
    "        for df in cvtest_normalized:\n",
    "            df[f] = df[f].clip(0, 1)\n",
    "    elif 'interest' in f or f == 'listing_id' or f == 'index':\n",
    "        continue\n",
    "    elif f == 'created' or train_df[f].dtype == 'O':\n",
    "        train_df_normalized.drop(f, axis=1, inplace=True)\n",
    "        for df in cvtest_normalized:\n",
    "            df.drop(f, axis=1, inplace=True)\n",
    "        continue\n",
    "    else:\n",
    "        #print(f, train_df[f].min(), train_df[f].max(), test_df[f].min(), test_df[f].max())\n",
    "        scaler[f] = sklearn.preprocessing.StandardScaler()\n",
    "        train_df_normalized[f] = scaler[f].fit_transform(train_df_normalized[f].values.reshape(-1,1))[:,0]\n",
    "        for df in cvtest_normalized:\n",
    "            df[f] = scaler[f].transform(df[f].values.reshape(-1,1))[:,0]\n",
    "        \n",
    "    normalized_keys.append(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models begin here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fl = normalized_keys.copy() + m_build.get_features() + m_mgr.get_features() \n",
    "\n",
    "#for f in ['density_exp01', 'density_exp005', 'density_lin005', 'density_gaussian001', 'density_gaussian', 'density_gaussian01', 'density_gaussian02', 'density_gaussian04']:\n",
    "#    fl.remove(f)\n",
    "    \n",
    "#fl.append('density_gaussian02')\n",
    "#fl.append('density_exp01')\n",
    "\n",
    "\n",
    "fl.remove('predicted_price_ratio')\n",
    "fl.remove('manager_building0_rate')\n",
    "fl.remove('manager_shortdesc_rate')\n",
    "fl.remove('manager_0feature_rate')\n",
    "#fl.append('manager_sort_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.583326595675\n",
      "30 0.564583867318\n",
      "40 0.55640282163\n",
      "50 0.55297015512\n",
      "60 0.5522085791\n",
      "70 0.551036046135\n",
      "80 0.548456980448\n",
      "90 0.548120494467\n",
      "100 0.547398887508\n",
      "110 0.544103625174\n",
      "120 0.543885010018\n",
      "130 0.544056941458\n",
      "140 0.54390063626\n",
      "150 0.543760753053\n",
      "160 0.543396538985\n",
      "170 0.543209339341\n",
      "180 0.543164062785\n",
      "190 0.542978549216\n",
      "200 0.542855772845\n",
      "210 0.543000699285\n",
      "220 0.542942881345\n",
      "230 0.542866927348\n",
      "240 0.542786932211\n",
      "250 0.542523391965\n",
      "260 0.542565326172\n",
      "270 0.542638907563\n",
      "280 0.54240001092\n",
      "290 0.542447548681\n",
      "300 0.542322008059\n",
      "310 0.542182701203\n",
      "320 0.542270802642\n",
      "330 0.542336732247\n",
      "340 0.542359290234\n",
      "350 0.542300408339\n",
      "360 0.54224689899\n",
      "0 0.54225151966\n",
      "20 0.562783574225\n",
      "30 0.548940895073\n",
      "40 0.54181185985\n",
      "50 0.541158801244\n",
      "60 0.536130767212\n",
      "70 0.535276797363\n",
      "80 0.534634191309\n",
      "90 0.533877558573\n",
      "100 0.533935561793\n",
      "110 0.533680906437\n",
      "120 0.533434391824\n",
      "130 0.533563194397\n",
      "140 0.533453484687\n",
      "150 0.533840530709\n",
      "160 0.533867656229\n",
      "170 0.534021518884\n",
      "1 0.534020801947\n",
      "20 0.581065021749\n",
      "30 0.567104196892\n",
      "40 0.561966914781\n",
      "50 0.560780961077\n",
      "60 0.559883134769\n",
      "70 0.559798202296\n",
      "80 0.559824806949\n",
      "90 0.556573024527\n",
      "100 0.556363028813\n",
      "110 0.555279292596\n",
      "120 0.555371860471\n",
      "130 0.554880342154\n",
      "140 0.554479990089\n",
      "150 0.554159784638\n",
      "160 0.553850745848\n",
      "170 0.553841967563\n",
      "180 0.553713775747\n",
      "190 0.553578098739\n",
      "200 0.55374881907\n",
      "210 0.553489736269\n",
      "220 0.55326695587\n",
      "230 0.552938222335\n",
      "240 0.553020986018\n",
      "250 0.553026068486\n",
      "260 0.552959724985\n",
      "270 0.553111571617\n",
      "280 0.553161002829\n",
      "2 0.553161002829\n",
      "20 0.578229223158\n",
      "30 0.555197172787\n",
      "40 0.544756684931\n",
      "50 0.542575196754\n",
      "60 0.537883203802\n",
      "70 0.537039498183\n",
      "80 0.537024055324\n",
      "90 0.53650875323\n",
      "100 0.53613324296\n",
      "110 0.535639719436\n",
      "120 0.535070599762\n",
      "130 0.535057540713\n",
      "140 0.53486864125\n",
      "150 0.534871004532\n",
      "160 0.53469699692\n",
      "170 0.534779934021\n",
      "180 0.534756825351\n",
      "190 0.53488130408\n",
      "200 0.534973703974\n",
      "210 0.534663816394\n",
      "220 0.53461253022\n",
      "230 0.534636041631\n",
      "240 0.534600009185\n",
      "250 0.534468238843\n",
      "260 0.534389680192\n",
      "270 0.53435420039\n",
      "280 0.534360791867\n",
      "290 0.534124690113\n",
      "300 0.533993792513\n",
      "310 0.53392397759\n",
      "320 0.533825480635\n",
      "330 0.533920006369\n",
      "340 0.533957016486\n",
      "350 0.533963494517\n",
      "360 0.534028083067\n",
      "370 0.534104233505\n",
      "3 0.534104465691\n",
      "20 0.561290957294\n",
      "30 0.552537609844\n",
      "40 0.550273801026\n",
      "50 0.546055169757\n",
      "60 0.545341194622\n",
      "70 0.544762377792\n",
      "80 0.545337594656\n",
      "90 0.54530081966\n",
      "100 0.54499010043\n",
      "110 0.544512647803\n",
      "120 0.544640565763\n",
      "130 0.544987138375\n",
      "140 0.544987325486\n",
      "150 0.544647371472\n",
      "160 0.544413032983\n",
      "170 0.544429358433\n",
      "180 0.544313543677\n",
      "190 0.544202514081\n",
      "200 0.544090518446\n",
      "210 0.544068915668\n",
      "220 0.543878450701\n",
      "230 0.543670319656\n",
      "240 0.543678987666\n",
      "250 0.543644955547\n",
      "260 0.543527044093\n",
      "270 0.543448000535\n",
      "280 0.543397094819\n",
      "290 0.543317170962\n",
      "300 0.543130129912\n",
      "310 0.543179524876\n",
      "320 0.543183938801\n",
      "330 0.543302750131\n",
      "340 0.543164052025\n",
      "350 0.543040585011\n",
      "360 0.542905006679\n",
      "370 0.543029878136\n",
      "380 0.543009262076\n",
      "390 0.542911897401\n",
      "400 0.542816423949\n",
      "410 0.542783278916\n",
      "420 0.542763489198\n",
      "430 0.542770826272\n",
      "440 0.542859408146\n",
      "450 0.542828698009\n",
      "460 0.542808545945\n",
      "470 0.542842700015\n",
      "4 0.542845939345\n",
      "combined:  0.541276650507\n",
      "106.8114025592804\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df_normalized.loc[tr_index])\n",
    "        cv_valid.append(train_df_normalized.loc[val_index])\n",
    "\n",
    "models = []\n",
    "cv_preds = []\n",
    "df_cvpreds = []\n",
    "\n",
    "for f in range(5):\n",
    "    #dset = lgbm.Dataset(cv_train[f][fl], cv_train[f].interest_cat, silent=True)\n",
    "    #dset_val = lgbm.Dataset(cv_valid[f][fl], cv_valid[f].interest_cat, silent=True)\n",
    "    #models.append(lgbm.train(lgbm_params, dset, early_stopping_rounds=100, verbose_eval=False, valid_sets=dset_val, num_boost_round=2000))\n",
    "\n",
    "    models.append(sklearn.ensemble.RandomForestClassifier(n_estimators=10, min_samples_split=8, min_samples_leaf=4, \n",
    "                                                          n_jobs=-1, class_weight=None, random_state=0))\n",
    "    models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "    best = None\n",
    "    \n",
    "    for nest in range(20, 2000, 10):\n",
    "        models[-1].set_params(warm_start = True, n_estimators=nest)\n",
    "        models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "        preds = models[-1].predict_proba(cv_valid[f][fl].values)\n",
    "        score = sklearn.metrics.log_loss(cv_valid[f].interest_cat, preds)\n",
    "        \n",
    "        print(nest, score)\n",
    "\n",
    "        if best is None or score < best[0]:\n",
    "            best = (score, nest)\n",
    "        elif nest - best[1] >= 50:\n",
    "            break\n",
    "            \n",
    "    #models[-1].set_params(n_estimators = best[1])\n",
    "    \n",
    "    #print('done training')\n",
    "    \n",
    "    cv_preds.append(models[-1].predict_proba(cv_valid[f][fl].values))\n",
    "\n",
    "    df_cvpreds.append(pd.DataFrame(cv_preds[f], columns=['low', 'medium', 'high']))\n",
    "    df_cvpreds[f].index = cv_valid[f].index\n",
    "    df_cvpreds[f]['interest_cat'] = cv_valid[f].interest_cat\n",
    "    df_cvpreds[f]['listing_id'] = cv_valid[f].listing_id\n",
    "\n",
    "    df_cvpreds[f].set_index('listing_id', inplace=True)\n",
    "    print(f, sklearn.metrics.log_loss(df_cvpreds[f].interest_cat, df_cvpreds[f][['low', 'medium', 'high']]))\n",
    "\n",
    "df_cvpreds = pd.concat(df_cvpreds)\n",
    "\n",
    "tgts = ['low', 'medium', 'high']\n",
    "\n",
    "print('combined: ', sklearn.metrics.log_loss(df_cvpreds.interest_cat, df_cvpreds[tgts]))\n",
    "\n",
    "end = time.time()\n",
    "print(end  - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testpreds = []\n",
    "for i, m in enumerate(models):\n",
    "    testpreds.append(m.predict_proba(cvtest_normalized[i][fl]))\n",
    "    \n",
    "f = np.array(testpreds).mean(axis=0)\n",
    "df_testpreds = pd.DataFrame(f, columns=['low', 'medium', 'high'])\n",
    "df_testpreds.index = test_df.index\n",
    "df_testpreds['listing_id'] = test_df.listing_id\n",
    "df_testpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "df_output = pd.concat([df_testpreds, df_cvpreds[tgts]])\n",
    "df_output.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fold = []\n",
    "for i in range(len(testpreds)):\n",
    "    df_fold.append(pd.DataFrame(testpreds[i]))\n",
    "    df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "    df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "    df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "pickle.dump((df_output, df_fold), open('model-output-rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.292096527436\n",
      "30 0.27158341902\n",
      "40 0.264031400668\n",
      "50 0.260278668073\n",
      "60 0.258340367339\n",
      "70 0.257256241264\n",
      "80 0.256278995325\n",
      "90 0.255620284908\n",
      "100 0.255145913323\n",
      "110 0.254906806619\n",
      "120 0.254613388379\n",
      "130 0.254556479169\n",
      "140 0.254476706799\n",
      "150 0.254357550832\n",
      "160 0.254319593032\n",
      "170 0.254194507073\n",
      "180 0.254108090616\n",
      "190 0.253921341687\n",
      "200 0.253864447126\n",
      "210 0.253780455416\n",
      "220 0.253819769413\n",
      "230 0.253767379979\n",
      "240 0.253785431681\n",
      "250 0.253761105406\n",
      "260 0.253740080722\n",
      "270 0.253761059263\n",
      "280 0.25375415227\n",
      "290 0.253710537549\n",
      "300 0.253675982788\n",
      "310 0.253636129461\n",
      "320 0.253587363658\n",
      "330 0.253578664685\n",
      "340 0.253577816128\n",
      "350 0.253545655204\n",
      "360 0.253587681629\n",
      "370 0.253598081195\n",
      "380 0.253641764732\n",
      "390 0.253668734815\n",
      "400 0.253672682618\n",
      "0\n",
      "20 0.288663671028\n",
      "30 0.269145129711\n",
      "40 0.261705426042\n",
      "50 0.257644651819\n",
      "60 0.255716143771\n",
      "70 0.254316551319\n",
      "80 0.253379513614\n",
      "90 0.252792486215\n",
      "100 0.252399287617\n",
      "110 0.252110819435\n",
      "120 0.25183553323\n",
      "130 0.251595262932\n",
      "140 0.2514430371\n",
      "150 0.251363101497\n",
      "160 0.251331927216\n",
      "170 0.251231358171\n",
      "180 0.251229292031\n",
      "190 0.251189188387\n",
      "200 0.251157898452\n",
      "210 0.251102108538\n",
      "220 0.251070116779\n",
      "230 0.251012631391\n",
      "240 0.250991117624\n",
      "250 0.250915933825\n",
      "260 0.250904907014\n",
      "270 0.250883708858\n",
      "280 0.250830066884\n",
      "290 0.250738903935\n",
      "300 0.25075216601\n",
      "310 0.250735592478\n",
      "320 0.250724483593\n",
      "330 0.250712536064\n",
      "340 0.250716903534\n",
      "350 0.250737307891\n",
      "360 0.250769685447\n",
      "370 0.250739842698\n",
      "380 0.250699324154\n",
      "390 0.250678117982\n",
      "400 0.250654393346\n",
      "410 0.250638374331\n",
      "420 0.250602163605\n",
      "430 0.250606822425\n",
      "440 0.250613238692\n",
      "450 0.250632343474\n",
      "460 0.250633719966\n",
      "470 0.250651342121\n",
      "1\n",
      "20 0.290728218853\n",
      "30 0.270090446308\n",
      "40 0.26200313198\n",
      "50 0.258193734273\n",
      "60 0.255989014562\n",
      "70 0.254811633243\n",
      "80 0.253681111082\n",
      "90 0.253203097308\n",
      "100 0.252681203667\n",
      "110 0.25253607403\n",
      "120 0.25221657199\n",
      "130 0.25220297189\n",
      "140 0.251956246097\n",
      "150 0.251761179596\n",
      "160 0.251665499285\n",
      "170 0.251544226367\n",
      "180 0.251417933513\n",
      "190 0.251379921165\n",
      "200 0.251300335463\n",
      "210 0.251230261546\n",
      "220 0.251092773244\n",
      "230 0.25103111302\n",
      "240 0.251027699221\n",
      "250 0.250911459031\n",
      "260 0.250812126883\n",
      "270 0.250813353346\n",
      "280 0.250776996921\n",
      "290 0.250767935637\n",
      "300 0.250799775671\n",
      "310 0.250786670838\n",
      "320 0.250745889336\n",
      "330 0.250706696559\n",
      "340 0.250660843042\n",
      "350 0.250619661697\n",
      "360 0.25058727034\n",
      "370 0.250588085369\n",
      "380 0.250561649487\n",
      "390 0.250566989561\n",
      "400 0.250555367458\n",
      "410 0.250546774583\n",
      "420 0.250537658781\n",
      "430 0.250506466141\n",
      "440 0.250523005416\n",
      "450 0.250552987965\n",
      "460 0.250554599387\n",
      "470 0.250495331231\n",
      "480 0.250505600383\n",
      "490 0.250516069046\n",
      "500 0.250506750367\n",
      "510 0.250515921321\n",
      "520 0.25050412628\n",
      "2\n",
      "20 0.292519255183\n",
      "30 0.272364145534\n",
      "40 0.265123020429\n",
      "50 0.261619978587\n",
      "60 0.2594816275\n",
      "70 0.258091070286\n",
      "80 0.257361566746\n",
      "90 0.256906541566\n",
      "100 0.256119764913\n",
      "110 0.255910837938\n",
      "120 0.255515574327\n",
      "130 0.255303915242\n",
      "140 0.255277545892\n",
      "150 0.255069583023\n",
      "160 0.254869947336\n",
      "170 0.254802933986\n",
      "180 0.254608872088\n",
      "190 0.254545208054\n",
      "200 0.254507767058\n",
      "210 0.254505530924\n",
      "220 0.254519274059\n",
      "230 0.254442178245\n",
      "240 0.25440531127\n",
      "250 0.25435110239\n",
      "260 0.254318631332\n",
      "270 0.254302263911\n",
      "280 0.254268191967\n",
      "290 0.254222208893\n",
      "300 0.254222212093\n",
      "310 0.25418427338\n",
      "320 0.254143289261\n",
      "330 0.254106367775\n",
      "340 0.254040016274\n",
      "350 0.253976828892\n",
      "360 0.253918581181\n",
      "370 0.253912962479\n",
      "380 0.253884793225\n",
      "390 0.25388197996\n",
      "400 0.253853957961\n",
      "410 0.253860413858\n",
      "420 0.253839425352\n",
      "430 0.253843977321\n",
      "440 0.253801808635\n",
      "450 0.253840304854\n",
      "460 0.253834744361\n",
      "470 0.253796474512\n",
      "480 0.253781248444\n",
      "490 0.253802767695\n",
      "500 0.253786743513\n",
      "510 0.253781921602\n",
      "520 0.253750070407\n",
      "530 0.253744075553\n",
      "540 0.253722467468\n",
      "550 0.253715523742\n",
      "560 0.253696303681\n",
      "570 0.25367324204\n",
      "580 0.253682224606\n",
      "590 0.253726785829\n",
      "600 0.253705875935\n",
      "610 0.253710557395\n",
      "620 0.253715211205\n",
      "3\n",
      "20 0.285993527193\n",
      "30 0.266573793439\n",
      "40 0.25879002171\n",
      "50 0.255533693649\n",
      "60 0.253832140916\n",
      "70 0.252539048909\n",
      "80 0.251929711247\n",
      "90 0.251491405077\n",
      "100 0.251021055009\n",
      "110 0.250746407271\n",
      "120 0.250581776695\n",
      "130 0.25041612223\n",
      "140 0.250263525502\n",
      "150 0.250110520749\n",
      "160 0.250152574155\n",
      "170 0.24998957347\n",
      "180 0.249872093185\n",
      "190 0.249812304586\n",
      "200 0.249795661493\n",
      "210 0.249745699932\n",
      "220 0.249789447723\n",
      "230 0.249795194914\n",
      "240 0.249724962986\n",
      "250 0.249694975462\n",
      "260 0.249701397706\n",
      "270 0.249702820665\n",
      "280 0.249690487538\n",
      "290 0.249698008351\n",
      "300 0.249674060573\n",
      "310 0.249679327351\n",
      "320 0.249693493052\n",
      "330 0.2496972194\n",
      "340 0.249652750728\n",
      "350 0.249668294997\n",
      "360 0.249675548951\n",
      "370 0.249684540692\n",
      "380 0.249620026422\n",
      "390 0.249601759359\n",
      "400 0.249569850334\n",
      "410 0.24952814133\n",
      "420 0.249520565015\n",
      "430 0.249538822391\n",
      "440 0.249559005194\n",
      "450 0.249579253835\n",
      "460 0.249531499628\n",
      "470 0.249539053219\n",
      "4\n",
      "combined:  0.251622570092\n",
      "733.7799310684204\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df_normalized.loc[tr_index])\n",
    "        cv_valid.append(train_df_normalized.loc[val_index])\n",
    "\n",
    "models = []\n",
    "cv_preds = []\n",
    "df_cvpreds = []\n",
    "\n",
    "for f in range(5):\n",
    "    #dset = lgbm.Dataset(cv_train[f][fl], cv_train[f].interest_cat, silent=True)\n",
    "    #dset_val = lgbm.Dataset(cv_valid[f][fl], cv_valid[f].interest_cat, silent=True)\n",
    "    #models.append(lgbm.train(lgbm_params, dset, early_stopping_rounds=100, verbose_eval=False, valid_sets=dset_val, num_boost_round=2000))\n",
    "\n",
    "    models.append(sklearn.ensemble.RandomForestRegressor(n_estimators=10, min_samples_split=8, min_samples_leaf=4, \n",
    "                                                          n_jobs=-1, random_state=0))\n",
    "    models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "    best = None\n",
    "    \n",
    "    for nest in range(20, 2000, 10):\n",
    "        models[-1].set_params(warm_start = True, n_estimators=nest)\n",
    "        models[-1].fit(cv_train[f][fl].values, cv_train[f].interest.values)\n",
    "    \n",
    "        preds = models[-1].predict(cv_valid[f][fl].values)\n",
    "        #score = sklearn.metrics.log_loss(cv_valid[f].interest, preds)\n",
    "        score = np.sqrt(sklearn.metrics.mean_squared_error(cv_valid[f].interest, preds))\n",
    "        \n",
    "        print(nest, score)\n",
    "\n",
    "        if best is None or score < best[0]:\n",
    "            best = (score, nest)\n",
    "        elif nest - best[1] >= 50:\n",
    "            break\n",
    "            \n",
    "    #models[-1].set_params(n_estimators = best[1])\n",
    "    \n",
    "    #print('done training')\n",
    "    \n",
    "    cv_preds.append(models[-1].predict(cv_valid[f][fl].values))\n",
    "\n",
    "    df_cvpreds.append(pd.DataFrame(cv_preds[f], columns=['prediction']))\n",
    "    df_cvpreds[f].index = cv_valid[f].index\n",
    "    df_cvpreds[f]['interest'] = cv_valid[f].interest\n",
    "    df_cvpreds[f]['listing_id'] = cv_valid[f].listing_id\n",
    "\n",
    "    df_cvpreds[f].set_index('listing_id', inplace=True)\n",
    "    print(f) #, np.sqrt(sklearn.metrics.mean_squared_error(cv_valid[f].interest, preds)))\n",
    "\n",
    "df_cvpreds = pd.concat(df_cvpreds)\n",
    "\n",
    "tgts = ['low', 'medium', 'high']\n",
    "\n",
    "print('combined: ', np.sqrt(sklearn.metrics.mean_squared_error(df_cvpreds.interest, df_cvpreds.prediction))) #sklearn.metrics.log_loss(df_cvpreds.interest_cat, df_cvpreds[tgts]))\n",
    "\n",
    "end = time.time()\n",
    "print(end  - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testpreds = []\n",
    "for i, m in enumerate(models):\n",
    "    testpreds.append(m.predict(cvtest_normalized[i][fl]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = np.array(testpreds).mean(axis=0)\n",
    "df_testpreds = pd.DataFrame(f, columns=['prediction'])\n",
    "df_testpreds.index = test_df.index\n",
    "df_testpreds['listing_id'] = test_df.listing_id\n",
    "df_testpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "df_output = pd.concat([df_testpreds, df_cvpreds[['prediction']]])\n",
    "df_output.sort_index(inplace=True)\n",
    "\n",
    "df_output.to_pickle('bag-model-rfr-v1.pkl')\n",
    "\n",
    "df_fold = []\n",
    "for i in range(len(testpreds)):\n",
    "    df_fold.append(pd.DataFrame(testpreds[i]))\n",
    "    df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "    df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "    df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "pickle.dump((df_output, df_fold), open('bagta-model-rfr-v1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.284186195488\n",
      "30 0.265958821954\n",
      "40 0.259247013231\n",
      "50 0.255700746787\n",
      "60 0.254181923445\n",
      "70 0.253214218752\n",
      "80 0.252695012866\n",
      "90 0.252027572135\n",
      "100 0.251631224067\n",
      "110 0.251455173568\n",
      "120 0.251306111599\n",
      "130 0.251134836482\n",
      "140 0.251014448712\n",
      "150 0.250942882723\n",
      "160 0.250903977167\n",
      "170 0.250743492843\n",
      "180 0.250684503264\n",
      "190 0.250643587619\n",
      "200 0.250566978491\n",
      "210 0.25058266343\n",
      "220 0.25055057091\n",
      "230 0.250530526918\n",
      "240 0.250527243495\n",
      "250 0.250551237175\n",
      "260 0.250560912678\n",
      "270 0.250485336496\n",
      "280 0.250482299271\n",
      "290 0.250537845928\n",
      "300 0.250539261569\n",
      "310 0.250481284099\n",
      "320 0.250469261469\n",
      "330 0.250471813276\n",
      "340 0.250442490443\n",
      "350 0.250460725332\n",
      "360 0.250453082106\n",
      "370 0.250426486544\n",
      "380 0.250404520127\n",
      "390 0.250404315517\n",
      "400 0.250401116492\n",
      "410 0.250393721715\n",
      "420 0.250360003323\n",
      "430 0.250321644975\n",
      "440 0.250371296554\n",
      "450 0.250378230768\n",
      "460 0.250378768944\n",
      "470 0.250390197725\n",
      "480 0.250379463062\n",
      "0\n",
      "20 0.277909206138\n",
      "30 0.260961212184\n",
      "40 0.254957303532\n",
      "50 0.252181429124\n",
      "60 0.25054498715\n",
      "70 0.249493731192\n",
      "80 0.248997085677\n",
      "90 0.248600347234\n",
      "100 0.248320109586\n",
      "110 0.248004225282\n",
      "120 0.247835044231\n",
      "130 0.24782488548\n",
      "140 0.247692259476\n",
      "150 0.247625051149\n",
      "160 0.247644663031\n",
      "170 0.247641842889\n",
      "180 0.247599835406\n",
      "190 0.24755873364\n",
      "200 0.247516698521\n",
      "210 0.247611074128\n",
      "220 0.247589095626\n",
      "230 0.247585329012\n",
      "240 0.247555983698\n",
      "250 0.247578555147\n",
      "1\n",
      "20 0.279437848693\n",
      "30 0.262597021505\n",
      "40 0.256085189488\n",
      "50 0.252885016383\n",
      "60 0.251324123849\n",
      "70 0.250177741214\n",
      "80 0.249569798608\n",
      "90 0.24907969855\n",
      "100 0.248879226936\n",
      "110 0.248659361916\n",
      "120 0.248385725573\n",
      "130 0.248327560327\n",
      "140 0.248172488983\n",
      "150 0.248142117227\n",
      "160 0.248005135104\n",
      "170 0.247932404141\n",
      "180 0.247799044292\n",
      "190 0.247677460945\n",
      "200 0.247713640133\n",
      "210 0.247727829863\n",
      "220 0.247767096162\n",
      "230 0.247744626499\n",
      "240 0.247760678558\n",
      "2\n",
      "20 0.286311060095\n",
      "30 0.267857892859\n",
      "40 0.261177427306\n",
      "50 0.258316203734\n",
      "60 0.256563555497\n",
      "70 0.255549429323\n",
      "80 0.254903169957\n",
      "90 0.254342115395\n",
      "100 0.254152715173\n",
      "110 0.25382730177\n",
      "120 0.253439904966\n",
      "130 0.253307999208\n",
      "140 0.253122704541\n",
      "150 0.25302293974\n",
      "160 0.252954508119\n",
      "170 0.252931143902\n",
      "180 0.25297215171\n",
      "190 0.252880828962\n",
      "200 0.252814203959\n",
      "210 0.252785305549\n",
      "220 0.252713438838\n",
      "230 0.252728024135\n",
      "240 0.252654002036\n",
      "250 0.252671182776\n",
      "260 0.252676015832\n",
      "270 0.252710006793\n",
      "280 0.252658088195\n",
      "290 0.252630598003\n",
      "300 0.252597595952\n",
      "310 0.252607986677\n",
      "320 0.252603701801\n",
      "330 0.252584892507\n",
      "340 0.25257929267\n",
      "350 0.25255261029\n",
      "360 0.2525640472\n",
      "370 0.252548823099\n",
      "380 0.252545793087\n",
      "390 0.252516762755\n",
      "400 0.252511256166\n",
      "410 0.25250520446\n",
      "420 0.252489598999\n",
      "430 0.252481725793\n",
      "440 0.252477014857\n",
      "450 0.25249748863\n",
      "460 0.252462062143\n",
      "470 0.252454949075\n",
      "480 0.252453407567\n",
      "490 0.252436185586\n",
      "500 0.252438507632\n",
      "510 0.252436307846\n",
      "520 0.252460117115\n",
      "530 0.25250837519\n",
      "540 0.252502643942\n",
      "3\n",
      "20 0.279757520208\n",
      "30 0.262314917827\n",
      "40 0.255272604591\n",
      "50 0.252270190604\n",
      "60 0.250580830838\n",
      "70 0.249558192435\n",
      "80 0.24878338172\n",
      "90 0.248221700707\n",
      "100 0.247886811001\n",
      "110 0.247661978421\n",
      "120 0.247519596268\n",
      "130 0.247443389607\n",
      "140 0.247308986651\n",
      "150 0.247295058239\n",
      "160 0.247277008966\n",
      "170 0.247183701174\n",
      "180 0.247058857609\n",
      "190 0.247099345959\n",
      "200 0.247019333104\n",
      "210 0.24694931582\n",
      "220 0.246895420869\n",
      "230 0.246870235678\n",
      "240 0.246845654676\n",
      "250 0.246870588151\n",
      "260 0.246904954677\n",
      "270 0.246960761029\n",
      "280 0.246956366469\n",
      "290 0.246925393441\n",
      "4\n",
      "combined:  0.249038188226\n",
      "335.64626002311707\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreesRegressor \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df_normalized.loc[tr_index])\n",
    "        cv_valid.append(train_df_normalized.loc[val_index])\n",
    "\n",
    "models = []\n",
    "cv_preds = []\n",
    "df_cvpreds = []\n",
    "\n",
    "for f in range(5):\n",
    "    models.append(sklearn.ensemble.ExtraTreesRegressor(n_estimators=10, min_samples_split=8, min_samples_leaf=4, \n",
    "                                                          n_jobs=-1, random_state=0))\n",
    "    models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "    best = None\n",
    "    \n",
    "    for nest in range(20, 2000, 10):\n",
    "        models[-1].set_params(warm_start = True, n_estimators=nest)\n",
    "        models[-1].fit(cv_train[f][fl].values, cv_train[f].interest.values)\n",
    "    \n",
    "        preds = models[-1].predict(cv_valid[f][fl].values)\n",
    "        #score = sklearn.metrics.log_loss(cv_valid[f].interest, preds)\n",
    "        score = np.sqrt(sklearn.metrics.mean_squared_error(cv_valid[f].interest, preds))\n",
    "        \n",
    "        print(nest, score)\n",
    "\n",
    "        if best is None or score < best[0]:\n",
    "            best = (score, nest)\n",
    "        elif nest - best[1] >= 50:\n",
    "            break\n",
    "            \n",
    "    cv_preds.append(models[-1].predict(cv_valid[f][fl].values))\n",
    "\n",
    "    df_cvpreds.append(pd.DataFrame(cv_preds[f], columns=['prediction']))\n",
    "    df_cvpreds[f].index = cv_valid[f].index\n",
    "    df_cvpreds[f]['interest'] = cv_valid[f].interest\n",
    "    df_cvpreds[f]['listing_id'] = cv_valid[f].listing_id\n",
    "\n",
    "    df_cvpreds[f].set_index('listing_id', inplace=True)\n",
    "    print(f) #, np.sqrt(sklearn.metrics.mean_squared_error(cv_valid[f].interest, preds)))\n",
    "\n",
    "df_cvpreds = pd.concat(df_cvpreds)\n",
    "\n",
    "tgts = ['low', 'medium', 'high']\n",
    "\n",
    "print('combined: ', np.sqrt(sklearn.metrics.mean_squared_error(df_cvpreds.interest, df_cvpreds.prediction))) #sklearn.metrics.log_loss(df_cvpreds.interest_cat, df_cvpreds[tgts]))\n",
    "\n",
    "end = time.time()\n",
    "print(end  - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testpreds = []\n",
    "for i, m in enumerate(models):\n",
    "    testpreds.append(m.predict(cvtest_normalized[i][fl]))\n",
    "    \n",
    "f = np.array(testpreds).mean(axis=0)\n",
    "df_testpreds = pd.DataFrame(f, columns=['prediction'])\n",
    "df_testpreds.index = test_df.index\n",
    "df_testpreds['listing_id'] = test_df.listing_id\n",
    "df_testpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "df_output = pd.concat([df_testpreds, df_cvpreds[['prediction']]])\n",
    "df_output.sort_index(inplace=True)\n",
    "\n",
    "#df_output.to_pickle('0423-model-etr-v1.pkl')\n",
    "\n",
    "df_fold = []\n",
    "for i in range(len(testpreds)):\n",
    "    df_fold.append(pd.DataFrame(testpreds[i]))\n",
    "    df_fold[-1]['listing_id'] = test_df.listing_id\n",
    "    df_fold[-1].sort_values('listing_id', inplace=True)\n",
    "    df_fold[-1].set_index('listing_id', inplace=True)\n",
    "\n",
    "pickle.dump((df_output, df_fold), open('bagta-model-etr-v1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6811957</th>\n",
       "      <td>0.410999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811958</th>\n",
       "      <td>0.609036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811960</th>\n",
       "      <td>0.409615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811964</th>\n",
       "      <td>0.538739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811965</th>\n",
       "      <td>0.683138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811966</th>\n",
       "      <td>0.615311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811971</th>\n",
       "      <td>0.345358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811973</th>\n",
       "      <td>0.376863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811974</th>\n",
       "      <td>0.515847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811975</th>\n",
       "      <td>0.392642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811983</th>\n",
       "      <td>0.234846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811984</th>\n",
       "      <td>0.271377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811985</th>\n",
       "      <td>0.243789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811988</th>\n",
       "      <td>0.571760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811990</th>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811992</th>\n",
       "      <td>0.048332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811995</th>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811997</th>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812000</th>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812002</th>\n",
       "      <td>0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812004</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812005</th>\n",
       "      <td>0.367943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812009</th>\n",
       "      <td>0.002533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812012</th>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812016</th>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812025</th>\n",
       "      <td>0.187664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812032</th>\n",
       "      <td>0.177738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812033</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812035</th>\n",
       "      <td>0.040983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812041</th>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714406</th>\n",
       "      <td>0.040422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714408</th>\n",
       "      <td>0.035560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714547</th>\n",
       "      <td>0.323051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724353</th>\n",
       "      <td>0.498246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724437</th>\n",
       "      <td>0.141485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724549</th>\n",
       "      <td>0.287647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724798</th>\n",
       "      <td>0.633203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724814</th>\n",
       "      <td>0.149701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724905</th>\n",
       "      <td>0.685805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731142</th>\n",
       "      <td>0.296909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731327</th>\n",
       "      <td>0.073033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731330</th>\n",
       "      <td>0.063305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742631</th>\n",
       "      <td>0.021842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742634</th>\n",
       "      <td>0.015231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742636</th>\n",
       "      <td>0.019382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742642</th>\n",
       "      <td>0.033682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742644</th>\n",
       "      <td>0.009324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742670</th>\n",
       "      <td>0.448826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742794</th>\n",
       "      <td>0.015639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742803</th>\n",
       "      <td>0.007231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742859</th>\n",
       "      <td>0.423839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742861</th>\n",
       "      <td>0.014970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748247</th>\n",
       "      <td>0.120063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748250</th>\n",
       "      <td>0.117711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748251</th>\n",
       "      <td>0.113714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748271</th>\n",
       "      <td>0.266247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748273</th>\n",
       "      <td>0.610056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753784</th>\n",
       "      <td>0.217309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754429</th>\n",
       "      <td>0.247798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761779</th>\n",
       "      <td>0.267889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124011 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prediction\n",
       "listing_id            \n",
       "6811957       0.410999\n",
       "6811958       0.609036\n",
       "6811960       0.409615\n",
       "6811964       0.538739\n",
       "6811965       0.683138\n",
       "6811966       0.615311\n",
       "6811971       0.345358\n",
       "6811973       0.376863\n",
       "6811974       0.515847\n",
       "6811975       0.392642\n",
       "6811983       0.234846\n",
       "6811984       0.271377\n",
       "6811985       0.243789\n",
       "6811988       0.571760\n",
       "6811990       0.002913\n",
       "6811992       0.048332\n",
       "6811995       0.001468\n",
       "6811997       0.000419\n",
       "6812000       0.024324\n",
       "6812002       0.010578\n",
       "6812004       0.000000\n",
       "6812005       0.367943\n",
       "6812009       0.002533\n",
       "6812012       0.000309\n",
       "6812016       0.000634\n",
       "6812025       0.187664\n",
       "6812032       0.177738\n",
       "6812033       0.000000\n",
       "6812035       0.040983\n",
       "6812041       0.002123\n",
       "...                ...\n",
       "7714406       0.040422\n",
       "7714408       0.035560\n",
       "7714547       0.323051\n",
       "7724353       0.498246\n",
       "7724437       0.141485\n",
       "7724549       0.287647\n",
       "7724798       0.633203\n",
       "7724814       0.149701\n",
       "7724905       0.685805\n",
       "7731142       0.296909\n",
       "7731327       0.073033\n",
       "7731330       0.063305\n",
       "7742631       0.021842\n",
       "7742634       0.015231\n",
       "7742636       0.019382\n",
       "7742642       0.033682\n",
       "7742644       0.009324\n",
       "7742670       0.448826\n",
       "7742794       0.015639\n",
       "7742803       0.007231\n",
       "7742859       0.423839\n",
       "7742861       0.014970\n",
       "7748247       0.120063\n",
       "7748250       0.117711\n",
       "7748251       0.113714\n",
       "7748271       0.266247\n",
       "7748273       0.610056\n",
       "7753784       0.217309\n",
       "7754429       0.247798\n",
       "7761779       0.267889\n",
       "\n",
       "[124011 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1.12296132847\n",
      "30 0.942927949061\n",
      "40 0.844550481435\n",
      "50 0.797762267704\n",
      "60 0.781118544176\n",
      "70 0.74291014053\n",
      "80 0.735813953207\n",
      "90 0.725778708524\n",
      "100 0.70352403112\n",
      "110 0.691069629282\n",
      "120 0.678172029392\n",
      "130 0.67497619837\n",
      "140 0.674740438006\n",
      "150 0.671048130923\n",
      "160 0.6705096715\n",
      "170 0.670215898684\n",
      "180 0.669729628895\n",
      "190 0.666112938059\n",
      "200 0.663259300476\n",
      "210 0.659661933232\n",
      "220 0.650185280136\n",
      "230 0.649839284451\n",
      "240 0.643923314802\n",
      "250 0.641127095932\n",
      "260 0.641433678261\n",
      "270 0.641525789111\n",
      "280 0.641486492967\n",
      "290 0.638562517295\n",
      "300 0.638519512836\n",
      "310 0.635716730599\n",
      "320 0.632999902856\n",
      "330 0.629937480721\n",
      "340 0.626842628871\n",
      "350 0.623850249736\n",
      "360 0.62094618567\n",
      "370 0.620845163869\n",
      "380 0.621167801268\n",
      "390 0.621128292064\n",
      "400 0.621091840209\n",
      "410 0.620958795269\n",
      "420 0.620816925182\n",
      "430 0.6179475613\n",
      "440 0.617827747385\n",
      "450 0.617820263081\n",
      "460 0.617769334832\n",
      "470 0.6176277653\n",
      "480 0.617659207137\n",
      "490 0.617575733492\n",
      "500 0.617419231484\n",
      "510 0.617287101022\n",
      "520 0.617173388505\n",
      "530 0.617194686212\n",
      "540 0.61432017067\n",
      "550 0.611588672624\n",
      "560 0.611509047252\n",
      "570 0.611427517184\n",
      "580 0.611334120612\n",
      "590 0.611373150902\n",
      "600 0.611306176219\n",
      "610 0.611092536397\n",
      "620 0.611180251979\n",
      "630 0.61106415847\n",
      "640 0.610959944597\n",
      "650 0.610938318333\n",
      "660 0.610844003849\n",
      "670 0.610756027815\n",
      "680 0.610747982488\n",
      "690 0.610665601763\n",
      "700 0.607833521745\n",
      "710 0.607776406854\n",
      "720 0.607757565377\n",
      "730 0.607818510202\n",
      "740 0.607888076719\n",
      "750 0.607843050913\n",
      "760 0.607741772671\n",
      "770 0.607750527192\n",
      "780 0.607788381863\n",
      "790 0.607772626284\n",
      "800 0.60770873325\n",
      "810 0.607763485246\n",
      "820 0.607754458216\n",
      "830 0.607787353974\n",
      "840 0.607797565373\n",
      "850 0.607825986548\n",
      "0 0.607828544787\n",
      "20 1.10185707068\n",
      "30 0.940357615011\n",
      "40 0.853368044373\n",
      "50 0.777234776211\n",
      "60 0.747959302898\n",
      "70 0.720702818221\n",
      "80 0.703610418258\n",
      "90 0.690133832248\n",
      "100 0.678175103677\n",
      "110 0.669014515232\n",
      "120 0.656960532383\n",
      "130 0.64487290796\n",
      "140 0.641455351607\n",
      "150 0.638787917673\n",
      "160 0.638440354228\n",
      "170 0.634663974477\n",
      "180 0.631481926523\n",
      "190 0.631158908466\n",
      "200 0.631167727761\n",
      "210 0.628357396904\n",
      "220 0.628679823583\n",
      "230 0.628503569146\n",
      "240 0.628559145908\n",
      "250 0.628334177603\n",
      "260 0.628607419494\n",
      "270 0.622853172476\n",
      "280 0.622757646894\n",
      "290 0.622827772797\n",
      "300 0.622503811004\n",
      "310 0.622510135138\n",
      "320 0.622457266134\n",
      "330 0.619686554758\n",
      "340 0.619839250155\n",
      "350 0.619980193387\n",
      "360 0.619694766805\n",
      "370 0.616822527337\n",
      "380 0.616659973874\n",
      "390 0.616512255606\n",
      "400 0.6165203991\n",
      "410 0.616422420893\n",
      "420 0.616267921785\n",
      "430 0.616100675155\n",
      "440 0.616145195551\n",
      "450 0.616161321951\n",
      "460 0.615974765542\n",
      "470 0.615899567967\n",
      "480 0.616023513858\n",
      "490 0.615948775805\n",
      "500 0.61598523593\n",
      "510 0.613021142595\n",
      "520 0.613113456034\n",
      "530 0.613246089813\n",
      "540 0.613058815803\n",
      "550 0.610188614129\n",
      "560 0.610232955589\n",
      "570 0.610096941896\n",
      "580 0.610074178384\n",
      "590 0.610003131693\n",
      "600 0.609978260475\n",
      "610 0.607291324069\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-1e556fc0ec01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    584\u001b[0m         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n\u001b[1;32m    585\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fl = ['price', 'manager_sort_level', 'latitude', 'longitude', 'bedrooms', 'bathrooms', 'density_exp005', 'predicted_price_diff', 'created_hour']\n",
    "\n",
    "\n",
    "# ET\n",
    "\n",
    "# RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df_normalized.loc[tr_index])\n",
    "        cv_valid.append(train_df_normalized.loc[val_index])\n",
    "\n",
    "models = []\n",
    "cv_preds = []\n",
    "df_cvpreds = []\n",
    "\n",
    "for f in range(5):\n",
    "    #dset = lgbm.Dataset(cv_train[f][fl], cv_train[f].interest_cat, silent=True)\n",
    "    #dset_val = lgbm.Dataset(cv_valid[f][fl], cv_valid[f].interest_cat, silent=True)\n",
    "    #models.append(lgbm.train(lgbm_params, dset, early_stopping_rounds=100, verbose_eval=False, valid_sets=dset_val, num_boost_round=2000))\n",
    "\n",
    "    models.append(sklearn.ensemble.ExtraTreesClassifier(n_estimators=10, max_features=len(fl),\n",
    "                                                          n_jobs=-1, class_weight=None, random_state=0))\n",
    "    models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "    best = None\n",
    "    \n",
    "    for nest in range(20, 2000, 10):\n",
    "        models[-1].set_params(warm_start = True, n_estimators=nest)\n",
    "        models[-1].fit(cv_train[f][fl].values, cv_train[f].interest_cat.values)\n",
    "    \n",
    "        preds = models[-1].predict_proba(cv_valid[f][fl].values)\n",
    "        score = sklearn.metrics.log_loss(cv_valid[f].interest_cat, preds)\n",
    "        \n",
    "        print(nest, score)\n",
    "\n",
    "        if best is None or score < best[0]:\n",
    "            best = (score, nest)\n",
    "        elif nest - best[1] >= 50:\n",
    "            break\n",
    "            \n",
    "    #models[-1].set_params(n_estimators = best[1])\n",
    "    \n",
    "    #print('done training')\n",
    "    \n",
    "    cv_preds.append(models[-1].predict_proba(cv_valid[f][fl].values))\n",
    "\n",
    "    df_cvpreds.append(pd.DataFrame(cv_preds[f], columns=['low', 'medium', 'high']))\n",
    "    df_cvpreds[f].index = cv_valid[f].index\n",
    "    df_cvpreds[f]['interest_cat'] = cv_valid[f].interest_cat\n",
    "    df_cvpreds[f]['listing_id'] = cv_valid[f].listing_id\n",
    "\n",
    "    df_cvpreds[f].set_index('listing_id', inplace=True)\n",
    "    print(f, sklearn.metrics.log_loss(df_cvpreds[f].interest_cat, df_cvpreds[f][['low', 'medium', 'high']]))\n",
    "\n",
    "df_cvpreds = pd.concat(df_cvpreds)\n",
    "\n",
    "tgts = ['low', 'medium', 'high']\n",
    "\n",
    "print('combined: ', sklearn.metrics.log_loss(df_cvpreds.interest_cat, df_cvpreds[tgts]))\n",
    "\n",
    "end = time.time()\n",
    "print(end  - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['desc_xp_count'] = train_df.description.apply(lambda x: x.count('!'))\n",
    "train_df['desc_xp_ratio'] = train_df.description.apply(lambda x: (x.count('!') / len(x)) if len(x) else 0)\n",
    "train_df['desc_xp_first'] = train_df.description.apply(lambda x: x.find('!') if len(x) else 0)\n",
    "train_df['desc_xp_inv_first'] = train_df.description.apply(lambda x: (len(x) - x.find('!')) if len(x) else 0)\n",
    "train_df['desc_xp_inv_mult'] = train_df.desc_xp_count * train_df.desc_xp_inv_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df.loc[tr_index])\n",
    "        cv_valid.append(train_df.loc[val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t4_params = {\n",
    "    'boosting_type': 'gbdt', 'objective': 'multiclass', 'nthread': -1, 'silent': True,\n",
    "    'num_leaves': 2**5, 'learning_rate': 0.02, 'max_depth': -1, 'metric': ['multi_logloss'],\n",
    "    'max_bin': 255, 'subsample_for_bin': 50000,\n",
    "    'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.6, 'reg_alpha': 1, 'reg_lambda': 0,\n",
    "    'min_split_gain': 0.25, 'min_child_weight': .5, 'min_child_samples': 20, 'scale_pos_weight': 1}\n",
    "\n",
    "lgbm_params = t4_params.copy()\n",
    "lgbm_params['num_class'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.552516080553\n",
      "1 0.557726118266\n",
      "2 0.561741087415\n",
      "3 0.550305671681\n",
      "4 0.556885845\n",
      "combined:  0.555834896702\n",
      "30.58432674407959\n"
     ]
    }
   ],
   "source": [
    "fl = ['price', 'manager_sort_level', 'latitude', 'longitude', 'bedrooms', 'bathrooms', 'density_exp005', 'predicted_price_diff', 'created_hour']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# prep CV\n",
    "\n",
    "cv_train = []\n",
    "cv_valid = []\n",
    "\n",
    "for tr_index, val_index in kf.split(train_df.index, train_df.interest_cat):\n",
    "        cv_train.append(train_df_normalized.loc[tr_index])\n",
    "        cv_valid.append(train_df_normalized.loc[val_index])\n",
    "\n",
    "models = []\n",
    "cv_preds = []\n",
    "df_cvpreds = []\n",
    "\n",
    "for f in range(5):\n",
    "    dset = lgbm.Dataset(cv_train[f][fl], cv_train[f].interest_cat, silent=True)\n",
    "    dset_val = lgbm.Dataset(cv_valid[f][fl], cv_valid[f].interest_cat, silent=True)\n",
    "    models.append(lgbm.train(lgbm_params, dset, early_stopping_rounds=100, verbose_eval=False, valid_sets=dset_val, num_boost_round=2000))\n",
    "\n",
    "    #print('done training')\n",
    "    \n",
    "    cv_preds.append(models[-1].predict(cv_valid[f][fl]))\n",
    "\n",
    "    df_cvpreds.append(pd.DataFrame(cv_preds[f], columns=['low', 'medium', 'high']))\n",
    "    df_cvpreds[f].index = cv_valid[f].index\n",
    "    df_cvpreds[f]['interest_cat'] = cv_valid[f].interest_cat\n",
    "    df_cvpreds[f]['listing_id'] = cv_valid[f].listing_id\n",
    "\n",
    "    df_cvpreds[f].set_index('listing_id', inplace=True)\n",
    "    print(f, sklearn.metrics.log_loss(df_cvpreds[f].interest_cat, df_cvpreds[f][['low', 'medium', 'high']]))\n",
    "\n",
    "df_cvpreds = pd.concat(df_cvpreds)\n",
    "\n",
    "tgts = ['low', 'medium', 'high']\n",
    "\n",
    "print('combined: ', sklearn.metrics.log_loss(df_cvpreds.interest_cat, df_cvpreds[tgts]))\n",
    "\n",
    "end = time.time()\n",
    "print(end  - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testpreds = []\n",
    "for i, m in enumerate(models):\n",
    "    testpreds.append(m.predict(cv_test[i][fl], num_iteration=m.best_iteration))\n",
    "    \n",
    "\n",
    "\n",
    "f = np.array(testpreds).mean(axis=0)\n",
    "df_testpreds = pd.DataFrame(f, columns=['low', 'medium', 'high'])\n",
    "df_testpreds.index = test_df.index\n",
    "df_testpreds['listing_id'] = test_df.listing_id\n",
    "df_testpreds.set_index('listing_id', inplace=True)\n",
    "\n",
    "df_output = pd.concat([df_testpreds, df_cvpreds[tgts]])\n",
    "df_output.sort_index(inplace=True)\n",
    "\n",
    "df_output.to_pickle('0423-minimod-lgbm-lf-v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrs = []\n",
    "for k in fl:\n",
    "    corrs.append((k, train_df[k].corr(train_df.interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time_stamp', -0.18019039565076073),\n",
       " ('display_address', -0.10638217137972825),\n",
       " ('address_ratio', -0.08435685614698217),\n",
       " ('half_bathroom', -0.082952509296588234),\n",
       " ('bathrooms', -0.08290129995713677),\n",
       " ('f_doorman', -0.080408870770706103),\n",
       " ('f_dogs_allowed', -0.069394270715112102),\n",
       " ('f_cats_allowed', -0.063240578842069212),\n",
       " ('f_garage', -0.061826833663457474),\n",
       " ('f_fitness_center', -0.041625294080062145),\n",
       " ('created_day', -0.035318942170163382),\n",
       " ('f_hardwood', -0.034737405598447645),\n",
       " ('f_fireplace', -0.028046029385565645),\n",
       " ('listing_id', -0.027602467182586288),\n",
       " ('density', -0.025715142282351982),\n",
       " ('price', -0.024422071937294336),\n",
       " ('f_gym_fitness', -0.022982979101316876),\n",
       " ('f_childrens_playroom', -0.022148888512394029),\n",
       " ('created_dayofyear', -0.01735538096319977),\n",
       " ('f_garden', -0.015741001576469776),\n",
       " ('f_bike_room', -0.01528765527419634),\n",
       " ('f_indoor_pool', -0.015284345235786326),\n",
       " ('f_brownstone', -0.014610002072087057),\n",
       " ('f_in_unit_washer_dryer', -0.01431467498798949),\n",
       " ('f_basement_storage', -0.012890619050425546),\n",
       " ('f_full_service_garage', -0.012212815755274534),\n",
       " ('f_attended_lobby', -0.011686935531385678),\n",
       " ('f_elevator', -0.011476862630146167),\n",
       " ('f_flex_2', -0.010534141055214741),\n",
       " ('f_deck', -0.0092224583955734189),\n",
       " ('f_children', -0.0086410666422274945),\n",
       " ('f_gym', -0.0082083729374437427),\n",
       " ('f_community_recreation_facilities', -0.0081500757799385544),\n",
       " ('f_green_building', -0.0071012278061486928),\n",
       " ('f_gym_in_building', -0.0065206020145217045),\n",
       " ('created_month', -0.0061852653157780805),\n",
       " ('f_common_parking_garage', -0.005147245710204181),\n",
       " ('longitude', -0.0050569641324356438),\n",
       " ('f_common_roof_deck', -0.0048727963704918538),\n",
       " ('f_courtyard', -0.0045883216661881969),\n",
       " ('f_billiards_room', -0.0038024320121321656),\n",
       " ('f_assigned_parking_space', -0.0033295860094368574),\n",
       " ('f__elev_lndry_bldg_', -0.0033295860094368461),\n",
       " ('f_building_common_outdoor_space', -0.0031056379002125881),\n",
       " ('f_business_center', -0.0029117495448706594),\n",
       " ('f_health_club', -0.0024321602612660054),\n",
       " ('f__exposed_brick_', -0.002322360662596785),\n",
       " ('f__housekeeping', -0.0021853517141903547),\n",
       " ('f_eat_in_kitchen', -0.0020386978680090261),\n",
       " ('f_common_terrace', -0.0018935202527496405),\n",
       " ('f_guarantors_accepted', -0.00094177186030862294),\n",
       " ('f_dry_cleaning_service', -0.00083470955370943886),\n",
       " ('f_common_garden', 1.3353799342668742e-05),\n",
       " ('f_backyard', 1.3353799342670887e-05),\n",
       " ('manager_id', 0.00056176989826598595),\n",
       " ('f__massive_1br_home_', 0.00067699465665070028),\n",
       " ('f_exposed_brick', 0.00074941493255863178),\n",
       " ('f__steps_to_the_park_', 0.00085359314689171237),\n",
       " ('f__cook', 0.00085359314689171357),\n",
       " ('f__2_blks_to_bedford_l_stop_', 0.00085359314689171465),\n",
       " ('f__elev_bldg_', 0.0011043518255861612),\n",
       " ('f_air_conditioning', 0.0016366854073997566),\n",
       " ('f__new_', 0.001828861177199033),\n",
       " ('location_cluster', 0.0018840451304264888),\n",
       " ('f__all_modern_', 0.0039695255502763191),\n",
       " ('f__gut_renovated_', 0.0039695255502763399),\n",
       " ('latitude', 0.0049073440510841951),\n",
       " ('f_cable_satellite_tv', 0.0080760774246337371),\n",
       " ('f_bike_storage', 0.0093330695720866969),\n",
       " ('f_common_backyard', 0.0096461282863857922),\n",
       " ('f__eat_in_kitchen_', 0.0096666060280858352),\n",
       " ('f__roomy_closets_', 0.010510177682981531),\n",
       " ('f_duplex', 0.011471394007603922),\n",
       " ('f_all_utilities_included', 0.013041615555849661),\n",
       " ('f_exclusive', 0.013136518550611027),\n",
       " ('f_gut_renovated', 0.01613081467205774),\n",
       " ('street_address', 0.019052348109443833),\n",
       " ('f_high_ceilings', 0.027371224128742402),\n",
       " ('f_common_outdoor_space', 0.028384918338367097),\n",
       " ('f_garden_patio', 0.028765444492280207),\n",
       " ('bedrooms', 0.03226416360187126),\n",
       " ('price_t', nan),\n",
       " ('price_per_room', nan),\n",
       " ('f__lndry_bldg_', 0.0018288611771990336),\n",
       " ('f__pets_ok_', 0.0036234866535139426),\n",
       " ('num_photos', 0.032443526361860056),\n",
       " ('num_features', 0.036203321687355482),\n",
       " ('f_dining_room', 0.042353666277858075),\n",
       " ('f_high_speed_internet', 0.043987016691473119),\n",
       " ('f_granite_kitchen', 0.045707149180638937),\n",
       " ('f_furnished', 0.05899236336182722),\n",
       " ('num_description_words', 0.059600303599038874),\n",
       " ('created_year', nan),\n",
       " ('density_exp01', -0.12664096547567719),\n",
       " ('density_gaussian02', -0.12655465248169487),\n",
       " ('f_laundry_room', -0.064347961338260956),\n",
       " ('f_pre_war', -0.061531609886662321),\n",
       " ('f_simplex', -0.056956086267372315),\n",
       " ('f_lowrise', -0.051771134728901054),\n",
       " ('f_publicoutdoor', -0.047563284386792269),\n",
       " ('f_pool', -0.041122569264336349),\n",
       " ('f_laundry', -0.025308403625298671),\n",
       " ('f_on_site_garage', -0.023947414414147546),\n",
       " ('fm_highrise', -0.023744291510852444),\n",
       " ('f_wifi_access', -0.023445677854650314),\n",
       " ('fm_laundry_in_unit', -0.023208695244561435),\n",
       " ('f_residents_lounge', -0.02296087881928718),\n",
       " ('f_patio', -0.021322315830169768),\n",
       " ('f_residents_garden', -0.019574778601242959),\n",
       " ('f_storage', -0.019218575986104974),\n",
       " ('f_valet', -0.01902145478783817),\n",
       " ('f_view', -0.01659705254991202),\n",
       " ('f_valet_parking', -0.01522521911415551),\n",
       " ('fm_concierge', -0.013053920330976699),\n",
       " ('f_live_in_superintendent', -0.012833359087058079),\n",
       " ('manager_sort_count', -0.012737214053333432),\n",
       " ('f_washer_dryer', -0.012383657755988382),\n",
       " ('f_outdoor_entertainment_space', -0.012212815755274534),\n",
       " ('f_washer_dryer_in_building', -0.012212815755274534),\n",
       " ('f_post_war', -0.011651821900543313),\n",
       " ('f_luxury_building', -0.010758356836323512),\n",
       " ('f_storage_room', -0.010369949748277719),\n",
       " ('f_mail_room', -0.0096898040282843729),\n",
       " ('f_outdoor_areas', -0.0095976459986946618),\n",
       " ('f_s_playroom', -0.0094450920737276112),\n",
       " ('f_virtual_doorman', -0.0088199779675000346),\n",
       " ('f_playroom_nursery', -0.00863453952189671),\n",
       " ('f_lounge_room', -0.0084396988819418275),\n",
       " ('f_lounge', -0.0079623892141454881),\n",
       " ('f_outdoor_pool', -0.0076393841256326882),\n",
       " ('f_rooftop_terrace', -0.006433744403303604),\n",
       " ('f_pets_allowed', -0.005890294507310768),\n",
       " ('f_live_work', -0.0056822860208247975),\n",
       " ('f_on_site_parking_lot', -0.0054402381060455049),\n",
       " ('f_media_room', -0.0052242965752724172),\n",
       " ('f_midrise', -0.0050523024457746479),\n",
       " ('f_parking', -0.0040952497852532813),\n",
       " ('f_private_parking', -0.0033295860094368574),\n",
       " ('f_on_site_parking_available', -0.0021853517141903547),\n",
       " ('f_private_laundry_room_on_every_floor', -0.0021853517141903547),\n",
       " ('f_video_intercom', -0.001742441328140536),\n",
       " ('f_on_site_parking', -0.0010789368190528032),\n",
       " ('f_playroom', -0.00048741135479725227),\n",
       " ('f_swimming_pool', -1.5576570199936427e-06),\n",
       " ('f_pets', 5.7442859210958739e-05),\n",
       " ('f_skylight', 6.1704612679377492e-05),\n",
       " ('f_private_backyard', 0.0010294415377170136),\n",
       " ('f_pet_friendly', 0.0012430227863272339),\n",
       " ('f_on_site_super', 0.0014427686355460187),\n",
       " ('f_private_terrace', 0.0017721051988860825),\n",
       " ('f_multi_level', 0.0020037309586999241),\n",
       " ('f_laundry_on_floor', 0.0020104606859344437),\n",
       " ('f_sundeck', 0.0023777623698929113),\n",
       " ('fm_central_air', 0.0026890996432358152),\n",
       " ('f_private_deck', 0.0028419835492644765),\n",
       " ('fm_roofdeck', 0.0041152504973862043),\n",
       " ('f_private_balcony', 0.0042523875576649106),\n",
       " ('f_shared_backyard', 0.0044205608484328227),\n",
       " ('f__gourmet_kitchen_', 0.0047942713626554275),\n",
       " ('f_package_room', 0.0048943939695505825),\n",
       " ('f_tenant_lounge', 0.0052429360945830516),\n",
       " ('f_marble_bathroom', 0.0055612887306597499),\n",
       " ('f_screening_room', 0.0055946887588022298),\n",
       " ('f__mr_clean_approved_', 0.0058894197300211433),\n",
       " ('f_s_kitchen_', 0.0067399181056956442),\n",
       " ('f_sublet', 0.0076622977446006981),\n",
       " ('f_washer_', 0.0077820041915908321),\n",
       " ('f__dryer', 0.0088266594544249288),\n",
       " ('f__walls_of_windows_', 0.0097443889947863935),\n",
       " ('f_party_room', 0.01098340935049859),\n",
       " ('f_private_roof_deck', 0.011321069890618856),\n",
       " ('f_wheelchair_access', 0.01166586068667011),\n",
       " ('f_microwave', 0.013644952320824692),\n",
       " ('f_pets_on_approval', 0.01457350539438552),\n",
       " ('manager_lazy_rate', 0.017201954295038208),\n",
       " ('f_on_site_laundry', 0.017211331947220233),\n",
       " ('f_new_construction', 0.017295140971784848),\n",
       " ('f_loft', 0.019483178894036963),\n",
       " ('f_no_pets', 0.023172154895398464),\n",
       " ('f_terrace', 0.024553590925121126),\n",
       " ('f_large_living_room', 0.024578224958028968),\n",
       " ('f_stainless_steel_appliances', 0.024920531211593405),\n",
       " ('f_balcony', 0.025347065565347576),\n",
       " ('f_laundry_in_unit', 0.026173174323366123),\n",
       " ('f_walk_in_closet', 0.026246890597488821),\n",
       " ('f_newly_renovated', 0.027189781168521433),\n",
       " ('f_shares_ok', 0.027281116820508038),\n",
       " ('f_parking_space', 0.029896300824096392),\n",
       " ('f_sauna', 0.032461086485931843),\n",
       " ('f__photos', 0.033161748690333184),\n",
       " ('f_actual_apt', 0.033161748690333184),\n",
       " ('f_short_term_allowed', 0.0419340840154293),\n",
       " ('f_private_outdoor_space', 0.044363533155687439),\n",
       " ('f_marble_bath', 0.044398264957522415),\n",
       " ('f_light', 0.045461906059264832),\n",
       " ('f_renovated', 0.052988112481286084),\n",
       " ('f_subway', 0.056982902177297019),\n",
       " ('f_outdoor_space', 0.058042658065696244),\n",
       " ('f_dishwasher', 0.060757389192004081),\n",
       " ('f_laundry_in_building', 0.090721668431859762),\n",
       " ('f_reduced_fee', 0.1009788272834992),\n",
       " ('f_hardwood_floors', 0.12875781444326573),\n",
       " ('building_id', 0.12909021814854379),\n",
       " ('f_no_fee', 0.14051729344363473),\n",
       " ('created_hour', 0.1637370746023887),\n",
       " ('predicted_price_diff', 0.34323636451459627)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(corrs, key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series.corr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3184.9364928241475"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[~(train_df.f_doorman == 1)].price.mean()"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 410,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
